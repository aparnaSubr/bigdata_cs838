
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_55b9a3fe-1249-4139-8914-72ea0250132c_964209850.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 1.036 seconds
Query ID = ubuntu_20161001103824_9d7ce841-2831-4fe2-bfef-13f5d5e6811d
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0156, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0156/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0156
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-10-01 10:38:37,497 Stage-1 map = 0%,  reduce = 0%
2016-10-01 10:38:50,135 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 22.7 sec
2016-10-01 10:38:51,187 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 73.15 sec
2016-10-01 10:38:55,373 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 91.33 sec
2016-10-01 10:38:56,434 Stage-1 map = 11%,  reduce = 0%, Cumulative CPU 95.61 sec
2016-10-01 10:38:57,480 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 103.3 sec
2016-10-01 10:39:00,598 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 117.87 sec
2016-10-01 10:39:04,778 Stage-1 map = 24%,  reduce = 0%, Cumulative CPU 138.98 sec
2016-10-01 10:39:05,834 Stage-1 map = 28%,  reduce = 0%, Cumulative CPU 145.34 sec
2016-10-01 10:39:06,882 Stage-1 map = 39%,  reduce = 0%, Cumulative CPU 164.04 sec
2016-10-01 10:39:07,946 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 177.47 sec
2016-10-01 10:39:09,012 Stage-1 map = 51%,  reduce = 0%, Cumulative CPU 187.62 sec
2016-10-01 10:39:10,115 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 196.73 sec
2016-10-01 10:39:17,513 Stage-1 map = 57%,  reduce = 0%, Cumulative CPU 216.13 sec
2016-10-01 10:39:18,555 Stage-1 map = 59%,  reduce = 0%, Cumulative CPU 235.75 sec
2016-10-01 10:39:19,599 Stage-1 map = 63%,  reduce = 0%, Cumulative CPU 264.61 sec
2016-10-01 10:39:20,648 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 267.98 sec
2016-10-01 10:39:21,693 Stage-1 map = 67%,  reduce = 0%, Cumulative CPU 272.15 sec
2016-10-01 10:39:22,738 Stage-1 map = 68%,  reduce = 0%, Cumulative CPU 277.04 sec
2016-10-01 10:39:24,824 Stage-1 map = 73%,  reduce = 0%, Cumulative CPU 282.48 sec
2016-10-01 10:39:25,873 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 286.39 sec
2016-10-01 10:39:27,948 Stage-1 map = 77%,  reduce = 0%, Cumulative CPU 295.57 sec
2016-10-01 10:39:28,999 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 299.05 sec
2016-10-01 10:39:30,042 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 306.38 sec
2016-10-01 10:39:31,145 Stage-1 map = 84%,  reduce = 0%, Cumulative CPU 312.85 sec
2016-10-01 10:39:32,202 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 316.46 sec
2016-10-01 10:39:33,245 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 318.01 sec
2016-10-01 10:39:34,299 Stage-1 map = 92%,  reduce = 0%, Cumulative CPU 328.17 sec
2016-10-01 10:39:35,334 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 332.94 sec
2016-10-01 10:39:38,434 Stage-1 map = 96%,  reduce = 0%, Cumulative CPU 340.85 sec
2016-10-01 10:39:39,473 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 343.39 sec
2016-10-01 10:39:40,517 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 346.62 sec
2016-10-01 10:39:41,557 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 347.42 sec
2016-10-01 10:39:53,033 Stage-1 map = 100%,  reduce = 11%, Cumulative CPU 371.51 sec
2016-10-01 10:39:54,119 Stage-1 map = 100%,  reduce = 15%, Cumulative CPU 379.87 sec
2016-10-01 10:39:55,185 Stage-1 map = 100%,  reduce = 24%, Cumulative CPU 399.54 sec
2016-10-01 10:39:56,241 Stage-1 map = 100%,  reduce = 38%, Cumulative CPU 419.87 sec
2016-10-01 10:39:57,290 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 451.47 sec
2016-10-01 10:40:03,596 Stage-1 map = 100%,  reduce = 53%, Cumulative CPU 458.47 sec
2016-10-01 10:40:04,651 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 477.86 sec
2016-10-01 10:40:05,709 Stage-1 map = 100%,  reduce = 68%, Cumulative CPU 490.75 sec
2016-10-01 10:40:06,761 Stage-1 map = 100%,  reduce = 72%, Cumulative CPU 497.53 sec
2016-10-01 10:40:07,839 Stage-1 map = 100%,  reduce = 81%, Cumulative CPU 516.68 sec
2016-10-01 10:40:08,877 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 548.33 sec
2016-10-01 10:40:09,911 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 554.8 sec
MapReduce Total cumulative CPU time: 9 minutes 14 seconds 800 msec
Ended Job = job_1475271333482_0156
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161001103824_9d7ce841-2831-4fe2-bfef-13f5d5e6811d.log
2016-10-01 10:40:14	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-01 10:40:15	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/55b9a3fe-1249-4139-8914-72ea0250132c/hive_2016-10-01_10-38-24_355_8455367134782962931-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-10-01 10:40:15	Uploaded 1 File to: file:/tmp/ubuntu/55b9a3fe-1249-4139-8914-72ea0250132c/hive_2016-10-01_10-38-24_355_8455367134782962931-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-10-01 10:40:15	End of local task; Time Taken: 1.33 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1475271333482_0157, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0157/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0157
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-10-01 10:40:20,998 Stage-30 map = 0%,  reduce = 0%
2016-10-01 10:40:33,409 Stage-30 map = 38%,  reduce = 0%, Cumulative CPU 23.13 sec
2016-10-01 10:40:36,509 Stage-30 map = 97%,  reduce = 0%, Cumulative CPU 35.22 sec
2016-10-01 10:40:37,544 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 35.76 sec
MapReduce Total cumulative CPU time: 35 seconds 760 msec
Ended Job = job_1475271333482_0157
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0158, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0158/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0158
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-10-01 10:40:43,509 Stage-3 map = 0%,  reduce = 0%
2016-10-01 10:40:52,892 Stage-3 map = 20%,  reduce = 0%, Cumulative CPU 4.89 sec
2016-10-01 10:40:54,965 Stage-3 map = 40%,  reduce = 0%, Cumulative CPU 9.24 sec
2016-10-01 10:40:56,006 Stage-3 map = 73%,  reduce = 0%, Cumulative CPU 25.08 sec
2016-10-01 10:40:57,053 Stage-3 map = 80%,  reduce = 0%, Cumulative CPU 25.59 sec
2016-10-01 10:40:59,130 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 28.8 sec
2016-10-01 10:41:02,251 Stage-3 map = 87%,  reduce = 0%, Cumulative CPU 31.96 sec
2016-10-01 10:41:05,348 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 35.01 sec
2016-10-01 10:41:08,450 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 38.23 sec
2016-10-01 10:41:15,706 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 45.41 sec
2016-10-01 10:41:26,056 Stage-3 map = 100%,  reduce = 71%, Cumulative CPU 60.17 sec
2016-10-01 10:41:29,161 Stage-3 map = 100%,  reduce = 78%, Cumulative CPU 66.57 sec
2016-10-01 10:41:32,261 Stage-3 map = 100%,  reduce = 85%, Cumulative CPU 72.89 sec
2016-10-01 10:41:35,366 Stage-3 map = 100%,  reduce = 93%, Cumulative CPU 79.35 sec
2016-10-01 10:41:38,480 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 86.23 sec
MapReduce Total cumulative CPU time: 1 minutes 26 seconds 230 msec
Ended Job = job_1475271333482_0158
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0159, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0159/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0159
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-10-01 10:41:45,418 Stage-4 map = 0%,  reduce = 0%
2016-10-01 10:41:53,652 Stage-4 map = 17%,  reduce = 0%, Cumulative CPU 4.23 sec
2016-10-01 10:41:54,688 Stage-4 map = 33%,  reduce = 0%, Cumulative CPU 9.53 sec
2016-10-01 10:41:56,753 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 18.62 sec
2016-10-01 10:42:03,953 Stage-4 map = 89%,  reduce = 0%, Cumulative CPU 43.46 sec
2016-10-01 10:42:04,982 Stage-4 map = 94%,  reduce = 0%, Cumulative CPU 44.8 sec
2016-10-01 10:42:06,010 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 46.53 sec
2016-10-01 10:42:16,344 Stage-4 map = 100%,  reduce = 36%, Cumulative CPU 54.03 sec
2016-10-01 10:42:17,378 Stage-4 map = 100%,  reduce = 71%, Cumulative CPU 61.56 sec
2016-10-01 10:42:19,436 Stage-4 map = 100%,  reduce = 75%, Cumulative CPU 64.82 sec
2016-10-01 10:42:20,465 Stage-4 map = 100%,  reduce = 78%, Cumulative CPU 68.06 sec
2016-10-01 10:42:22,523 Stage-4 map = 100%,  reduce = 81%, Cumulative CPU 71.26 sec
2016-10-01 10:42:23,559 Stage-4 map = 100%,  reduce = 84%, Cumulative CPU 74.46 sec
2016-10-01 10:42:25,625 Stage-4 map = 100%,  reduce = 88%, Cumulative CPU 77.73 sec
2016-10-01 10:42:26,658 Stage-4 map = 100%,  reduce = 91%, Cumulative CPU 80.92 sec
2016-10-01 10:42:28,728 Stage-4 map = 100%,  reduce = 97%, Cumulative CPU 87.63 sec
2016-10-01 10:42:31,812 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 90.42 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 420 msec
Ended Job = job_1475271333482_0159
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0160, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0160/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0160
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-10-01 10:42:37,800 Stage-5 map = 0%,  reduce = 0%
2016-10-01 10:42:47,055 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 4.15 sec
2016-10-01 10:42:55,311 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 29.99 sec
2016-10-01 10:42:58,411 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 36.5 sec
2016-10-01 10:42:59,464 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 38.99 sec
2016-10-01 10:43:10,792 Stage-5 map = 100%,  reduce = 69%, Cumulative CPU 51.66 sec
2016-10-01 10:43:12,856 Stage-5 map = 100%,  reduce = 72%, Cumulative CPU 54.93 sec
2016-10-01 10:43:13,893 Stage-5 map = 100%,  reduce = 75%, Cumulative CPU 57.39 sec
2016-10-01 10:43:15,965 Stage-5 map = 100%,  reduce = 77%, Cumulative CPU 60.6 sec
2016-10-01 10:43:17,000 Stage-5 map = 100%,  reduce = 81%, Cumulative CPU 63.69 sec
2016-10-01 10:43:19,075 Stage-5 map = 100%,  reduce = 87%, Cumulative CPU 70.17 sec
2016-10-01 10:43:22,163 Stage-5 map = 100%,  reduce = 93%, Cumulative CPU 76.81 sec
2016-10-01 10:43:25,252 Stage-5 map = 100%,  reduce = 99%, Cumulative CPU 83.2 sec
2016-10-01 10:43:26,284 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 84.61 sec
MapReduce Total cumulative CPU time: 1 minutes 24 seconds 610 msec
Ended Job = job_1475271333482_0160
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161001103824_9d7ce841-2831-4fe2-bfef-13f5d5e6811d.log
2016-10-01 10:43:31	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-01 10:43:33	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/55b9a3fe-1249-4139-8914-72ea0250132c/hive_2016-10-01_10-38-24_355_8455367134782962931-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-10-01 10:43:33	Uploaded 1 File to: file:/tmp/ubuntu/55b9a3fe-1249-4139-8914-72ea0250132c/hive_2016-10-01_10-38-24_355_8455367134782962931-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-10-01 10:43:33	End of local task; Time Taken: 1.685 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1475271333482_0161, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0161/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0161
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-10-01 10:43:38,726 Stage-18 map = 0%,  reduce = 0%
2016-10-01 10:43:54,155 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 22.08 sec
MapReduce Total cumulative CPU time: 22 seconds 80 msec
Ended Job = job_1475271333482_0161
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161001103824_9d7ce841-2831-4fe2-bfef-13f5d5e6811d.log
2016-10-01 10:43:59	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-01 10:44:00	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/55b9a3fe-1249-4139-8914-72ea0250132c/hive_2016-10-01_10-38-24_355_8455367134782962931-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-10-01 10:44:00	Uploaded 1 File to: file:/tmp/ubuntu/55b9a3fe-1249-4139-8914-72ea0250132c/hive_2016-10-01_10-38-24_355_8455367134782962931-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-10-01 10:44:00	End of local task; Time Taken: 1.317 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0162, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0162/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0162
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-10-01 10:44:06,071 Stage-8 map = 0%,  reduce = 0%
2016-10-01 10:44:16,386 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.25 sec
2016-10-01 10:44:18,454 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 8.71 sec
2016-10-01 10:44:24,665 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 10.58 sec
MapReduce Total cumulative CPU time: 10 seconds 580 msec
Ended Job = job_1475271333482_0162
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0163, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0163/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0163
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-10-01 10:44:30,446 Stage-9 map = 0%,  reduce = 0%
2016-10-01 10:44:35,602 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.09 sec
2016-10-01 10:44:41,773 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.24 sec
MapReduce Total cumulative CPU time: 2 seconds 240 msec
Ended Job = job_1475271333482_0163
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 554.8 sec   HDFS Read: 8124263543 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 35.76 sec   HDFS Read: 227005634 HDFS Write: 235481491 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 86.23 sec   HDFS Read: 316193609 HDFS Write: 293830102 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 90.42 sec   HDFS Read: 374559491 HDFS Write: 348836432 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 84.61 sec   HDFS Read: 391388819 HDFS Write: 419920413 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 22.08 sec   HDFS Read: 419945109 HDFS Write: 85556547 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 10.58 sec   HDFS Read: 85590149 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.24 sec   HDFS Read: 7071 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 46 seconds 720 msec
OK
Time taken: 378.518 seconds, Fetched: 32 row(s)
51.70user 5.01system 6:25.58elapsed 14%CPU (0avgtext+0avgdata 1145256maxresident)k
115432inputs+491800outputs (110major+193393minor)pagefaults 0swaps
