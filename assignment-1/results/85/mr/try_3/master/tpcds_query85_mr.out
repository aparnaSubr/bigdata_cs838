
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_128514c3-d389-4c2f-b664-6cc2792e0b80_1027519437.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 1.109 seconds
Query ID = ubuntu_20161001112300_48a68856-caa1-4882-b4d3-c3faee939f8f
Total jobs = 16
Stage-1 is selected by condition resolver.
Launching Job 1 out of 16
Number of reduce tasks not specified. Estimated from input data size: 32
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0174, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0174/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0174
Hadoop job information for Stage-1: number of mappers: 30; number of reducers: 32
2016-10-01 11:23:12,733 Stage-1 map = 0%,  reduce = 0%
2016-10-01 11:23:26,352 Stage-1 map = 1%,  reduce = 0%, Cumulative CPU 39.68 sec
2016-10-01 11:23:27,399 Stage-1 map = 2%,  reduce = 0%, Cumulative CPU 71.96 sec
2016-10-01 11:23:28,478 Stage-1 map = 3%,  reduce = 0%, Cumulative CPU 75.29 sec
2016-10-01 11:23:31,607 Stage-1 map = 5%,  reduce = 0%, Cumulative CPU 91.48 sec
2016-10-01 11:23:32,661 Stage-1 map = 18%,  reduce = 0%, Cumulative CPU 102.81 sec
2016-10-01 11:23:34,740 Stage-1 map = 19%,  reduce = 0%, Cumulative CPU 105.93 sec
2016-10-01 11:23:35,781 Stage-1 map = 20%,  reduce = 0%, Cumulative CPU 116.97 sec
2016-10-01 11:23:37,864 Stage-1 map = 21%,  reduce = 0%, Cumulative CPU 121.24 sec
2016-10-01 11:23:41,049 Stage-1 map = 29%,  reduce = 0%, Cumulative CPU 149.63 sec
2016-10-01 11:23:42,105 Stage-1 map = 38%,  reduce = 0%, Cumulative CPU 166.69 sec
2016-10-01 11:23:43,199 Stage-1 map = 46%,  reduce = 0%, Cumulative CPU 177.85 sec
2016-10-01 11:23:44,300 Stage-1 map = 53%,  reduce = 0%, Cumulative CPU 195.18 sec
2016-10-01 11:23:51,747 Stage-1 map = 54%,  reduce = 0%, Cumulative CPU 206.0 sec
2016-10-01 11:23:52,800 Stage-1 map = 56%,  reduce = 0%, Cumulative CPU 217.59 sec
2016-10-01 11:23:53,909 Stage-1 map = 58%,  reduce = 0%, Cumulative CPU 242.1 sec
2016-10-01 11:23:54,950 Stage-1 map = 66%,  reduce = 0%, Cumulative CPU 265.86 sec
2016-10-01 11:23:57,016 Stage-1 map = 69%,  reduce = 0%, Cumulative CPU 272.79 sec
2016-10-01 11:23:58,053 Stage-1 map = 70%,  reduce = 0%, Cumulative CPU 278.75 sec
2016-10-01 11:23:59,088 Stage-1 map = 71%,  reduce = 0%, Cumulative CPU 281.56 sec
2016-10-01 11:24:00,128 Stage-1 map = 75%,  reduce = 0%, Cumulative CPU 287.55 sec
2016-10-01 11:24:01,175 Stage-1 map = 78%,  reduce = 0%, Cumulative CPU 293.89 sec
2016-10-01 11:24:02,208 Stage-1 map = 81%,  reduce = 0%, Cumulative CPU 298.54 sec
2016-10-01 11:24:04,271 Stage-1 map = 82%,  reduce = 0%, Cumulative CPU 305.32 sec
2016-10-01 11:24:05,304 Stage-1 map = 83%,  reduce = 0%, Cumulative CPU 306.76 sec
2016-10-01 11:24:06,343 Stage-1 map = 85%,  reduce = 0%, Cumulative CPU 312.15 sec
2016-10-01 11:24:07,378 Stage-1 map = 86%,  reduce = 0%, Cumulative CPU 314.21 sec
2016-10-01 11:24:08,413 Stage-1 map = 89%,  reduce = 0%, Cumulative CPU 321.48 sec
2016-10-01 11:24:09,465 Stage-1 map = 91%,  reduce = 0%, Cumulative CPU 326.33 sec
2016-10-01 11:24:10,517 Stage-1 map = 94%,  reduce = 0%, Cumulative CPU 331.45 sec
2016-10-01 11:24:12,580 Stage-1 map = 95%,  reduce = 0%, Cumulative CPU 336.26 sec
2016-10-01 11:24:13,649 Stage-1 map = 97%,  reduce = 0%, Cumulative CPU 341.08 sec
2016-10-01 11:24:14,686 Stage-1 map = 98%,  reduce = 0%, Cumulative CPU 342.13 sec
2016-10-01 11:24:15,720 Stage-1 map = 99%,  reduce = 0%, Cumulative CPU 345.35 sec
2016-10-01 11:24:16,756 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 346.31 sec
2016-10-01 11:24:27,139 Stage-1 map = 100%,  reduce = 8%, Cumulative CPU 363.88 sec
2016-10-01 11:24:28,240 Stage-1 map = 100%,  reduce = 12%, Cumulative CPU 372.0 sec
2016-10-01 11:24:29,286 Stage-1 map = 100%,  reduce = 21%, Cumulative CPU 391.88 sec
2016-10-01 11:24:30,359 Stage-1 map = 100%,  reduce = 25%, Cumulative CPU 400.18 sec
2016-10-01 11:24:31,420 Stage-1 map = 100%,  reduce = 37%, Cumulative CPU 424.68 sec
2016-10-01 11:24:32,495 Stage-1 map = 100%,  reduce = 50%, Cumulative CPU 450.54 sec
2016-10-01 11:24:37,689 Stage-1 map = 100%,  reduce = 53%, Cumulative CPU 457.14 sec
2016-10-01 11:24:38,745 Stage-1 map = 100%,  reduce = 59%, Cumulative CPU 470.32 sec
2016-10-01 11:24:39,827 Stage-1 map = 100%,  reduce = 62%, Cumulative CPU 476.96 sec
2016-10-01 11:24:40,867 Stage-1 map = 100%,  reduce = 71%, Cumulative CPU 488.83 sec
2016-10-01 11:24:41,927 Stage-1 map = 100%,  reduce = 78%, Cumulative CPU 509.02 sec
2016-10-01 11:24:42,993 Stage-1 map = 100%,  reduce = 88%, Cumulative CPU 528.14 sec
2016-10-01 11:24:44,024 Stage-1 map = 100%,  reduce = 97%, Cumulative CPU 546.64 sec
2016-10-01 11:24:46,117 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 554.43 sec
MapReduce Total cumulative CPU time: 9 minutes 14 seconds 430 msec
Ended Job = job_1475271333482_0174
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161001112300_48a68856-caa1-4882-b4d3-c3faee939f8f.log
2016-10-01 11:24:50	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-01 11:24:51	Dump the side-table for tag: 1 with group count: 876 into file: file:/tmp/ubuntu/128514c3-d389-4c2f-b664-6cc2792e0b80/hive_2016-10-01_11-23-00_880_6789270517402734396-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable
2016-10-01 11:24:51	Uploaded 1 File to: file:/tmp/ubuntu/128514c3-d389-4c2f-b664-6cc2792e0b80/hive_2016-10-01_11-23-00_880_6789270517402734396-1/-local-10030/HashTable-Stage-30/MapJoin-mapfile91--.hashtable (17481 bytes)
2016-10-01 11:24:51	End of local task; Time Taken: 1.247 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1475271333482_0175, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0175/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0175
Hadoop job information for Stage-30: number of mappers: 4; number of reducers: 0
2016-10-01 11:24:57,537 Stage-30 map = 0%,  reduce = 0%
2016-10-01 11:25:11,093 Stage-30 map = 38%,  reduce = 0%, Cumulative CPU 23.13 sec
2016-10-01 11:25:14,234 Stage-30 map = 97%,  reduce = 0%, Cumulative CPU 36.58 sec
2016-10-01 11:25:15,275 Stage-30 map = 100%,  reduce = 0%, Cumulative CPU 37.29 sec
MapReduce Total cumulative CPU time: 37 seconds 290 msec
Ended Job = job_1475271333482_0175
Stage-41 is filtered out by condition resolver.
Stage-42 is filtered out by condition resolver.
Stage-3 is selected by condition resolver.
Launching Job 3 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0176, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0176/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0176
Hadoop job information for Stage-3: number of mappers: 5; number of reducers: 2
2016-10-01 11:25:21,517 Stage-3 map = 0%,  reduce = 0%
2016-10-01 11:25:31,835 Stage-3 map = 3%,  reduce = 0%, Cumulative CPU 7.23 sec
2016-10-01 11:25:32,866 Stage-3 map = 23%,  reduce = 0%, Cumulative CPU 11.11 sec
2016-10-01 11:25:33,898 Stage-3 map = 83%,  reduce = 0%, Cumulative CPU 25.51 sec
2016-10-01 11:25:38,006 Stage-3 map = 87%,  reduce = 0%, Cumulative CPU 31.8 sec
2016-10-01 11:25:41,102 Stage-3 map = 90%,  reduce = 0%, Cumulative CPU 34.87 sec
2016-10-01 11:25:44,200 Stage-3 map = 93%,  reduce = 0%, Cumulative CPU 38.09 sec
2016-10-01 11:25:49,338 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 43.79 sec
2016-10-01 11:26:00,649 Stage-3 map = 100%,  reduce = 72%, Cumulative CPU 59.02 sec
2016-10-01 11:26:03,736 Stage-3 map = 100%,  reduce = 79%, Cumulative CPU 65.47 sec
2016-10-01 11:26:06,825 Stage-3 map = 100%,  reduce = 86%, Cumulative CPU 71.86 sec
2016-10-01 11:26:09,913 Stage-3 map = 100%,  reduce = 93%, Cumulative CPU 78.26 sec
2016-10-01 11:26:12,992 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 84.4 sec
MapReduce Total cumulative CPU time: 1 minutes 24 seconds 400 msec
Ended Job = job_1475271333482_0176
Stage-39 is filtered out by condition resolver.
Stage-40 is filtered out by condition resolver.
Stage-4 is selected by condition resolver.
Launching Job 4 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0177, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0177/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0177
Hadoop job information for Stage-4: number of mappers: 6; number of reducers: 2
2016-10-01 11:26:19,783 Stage-4 map = 0%,  reduce = 0%
2016-10-01 11:26:28,101 Stage-4 map = 33%,  reduce = 0%, Cumulative CPU 8.47 sec
2016-10-01 11:26:31,203 Stage-4 map = 67%,  reduce = 0%, Cumulative CPU 18.7 sec
2016-10-01 11:26:37,409 Stage-4 map = 78%,  reduce = 0%, Cumulative CPU 40.19 sec
2016-10-01 11:26:38,462 Stage-4 map = 88%,  reduce = 0%, Cumulative CPU 43.47 sec
2016-10-01 11:26:39,503 Stage-4 map = 93%,  reduce = 0%, Cumulative CPU 45.81 sec
2016-10-01 11:26:40,537 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 48.73 sec
2016-10-01 11:26:51,914 Stage-4 map = 100%,  reduce = 72%, Cumulative CPU 63.62 sec
2016-10-01 11:26:55,015 Stage-4 map = 100%,  reduce = 78%, Cumulative CPU 70.01 sec
2016-10-01 11:26:58,112 Stage-4 map = 100%,  reduce = 85%, Cumulative CPU 76.39 sec
2016-10-01 11:27:01,219 Stage-4 map = 100%,  reduce = 92%, Cumulative CPU 82.88 sec
2016-10-01 11:27:04,318 Stage-4 map = 100%,  reduce = 99%, Cumulative CPU 89.64 sec
2016-10-01 11:27:05,349 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 90.92 sec
MapReduce Total cumulative CPU time: 1 minutes 30 seconds 920 msec
Ended Job = job_1475271333482_0177
Stage-37 is filtered out by condition resolver.
Stage-38 is filtered out by condition resolver.
Stage-5 is selected by condition resolver.
Launching Job 5 out of 16
Number of reduce tasks not specified. Estimated from input data size: 2
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0178, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0178/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0178
Hadoop job information for Stage-5: number of mappers: 3; number of reducers: 2
2016-10-01 11:27:12,135 Stage-5 map = 0%,  reduce = 0%
2016-10-01 11:27:20,485 Stage-5 map = 33%,  reduce = 0%, Cumulative CPU 4.26 sec
2016-10-01 11:27:28,747 Stage-5 map = 68%,  reduce = 0%, Cumulative CPU 29.85 sec
2016-10-01 11:27:31,859 Stage-5 map = 78%,  reduce = 0%, Cumulative CPU 36.3 sec
2016-10-01 11:27:34,968 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 42.14 sec
2016-10-01 11:27:46,311 Stage-5 map = 100%,  reduce = 52%, Cumulative CPU 50.36 sec
2016-10-01 11:27:49,412 Stage-5 map = 100%,  reduce = 73%, Cumulative CPU 58.25 sec
2016-10-01 11:27:51,481 Stage-5 map = 100%,  reduce = 76%, Cumulative CPU 61.58 sec
2016-10-01 11:27:52,520 Stage-5 map = 100%,  reduce = 79%, Cumulative CPU 64.73 sec
2016-10-01 11:27:54,589 Stage-5 map = 100%,  reduce = 82%, Cumulative CPU 68.02 sec
2016-10-01 11:27:55,626 Stage-5 map = 100%,  reduce = 85%, Cumulative CPU 71.25 sec
2016-10-01 11:27:57,695 Stage-5 map = 100%,  reduce = 88%, Cumulative CPU 74.51 sec
2016-10-01 11:27:58,735 Stage-5 map = 100%,  reduce = 91%, Cumulative CPU 77.75 sec
2016-10-01 11:28:00,815 Stage-5 map = 100%,  reduce = 94%, Cumulative CPU 81.07 sec
2016-10-01 11:28:01,849 Stage-5 map = 100%,  reduce = 97%, Cumulative CPU 83.81 sec
2016-10-01 11:28:03,929 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 87.06 sec
MapReduce Total cumulative CPU time: 1 minutes 27 seconds 60 msec
Ended Job = job_1475271333482_0178
Stage-35 is selected by condition resolver.
Stage-36 is filtered out by condition resolver.
Stage-6 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161001112300_48a68856-caa1-4882-b4d3-c3faee939f8f.log
2016-10-01 11:28:08	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-01 11:28:09	Dump the side-table for tag: 1 with group count: 365 into file: file:/tmp/ubuntu/128514c3-d389-4c2f-b664-6cc2792e0b80/hive_2016-10-01_11-23-00_880_6789270517402734396-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable
2016-10-01 11:28:09	Uploaded 1 File to: file:/tmp/ubuntu/128514c3-d389-4c2f-b664-6cc2792e0b80/hive_2016-10-01_11-23-00_880_6789270517402734396-1/-local-10014/HashTable-Stage-18/MapJoin-mapfile11--.hashtable (7963 bytes)
2016-10-01 11:28:09	End of local task; Time Taken: 1.799 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 7 out of 16
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1475271333482_0179, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0179/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0179
Hadoop job information for Stage-18: number of mappers: 2; number of reducers: 0
2016-10-01 11:28:15,455 Stage-18 map = 0%,  reduce = 0%
2016-10-01 11:28:29,946 Stage-18 map = 100%,  reduce = 0%, Cumulative CPU 22.16 sec
MapReduce Total cumulative CPU time: 22 seconds 160 msec
Ended Job = job_1475271333482_0179
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161001112300_48a68856-caa1-4882-b4d3-c3faee939f8f.log
2016-10-01 11:28:34	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-01 11:28:35	Dump the side-table for tag: 1 with group count: 39 into file: file:/tmp/ubuntu/128514c3-d389-4c2f-b664-6cc2792e0b80/hive_2016-10-01_11-23-00_880_6789270517402734396-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-10-01 11:28:35	Uploaded 1 File to: file:/tmp/ubuntu/128514c3-d389-4c2f-b664-6cc2792e0b80/hive_2016-10-01_11-23-00_880_6789270517402734396-1/-local-10012/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1662 bytes)
2016-10-01 11:28:35	End of local task; Time Taken: 1.335 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 8 out of 16
Number of reduce tasks not specified. Estimated from input data size: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0180, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0180/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0180
Hadoop job information for Stage-8: number of mappers: 1; number of reducers: 1
2016-10-01 11:28:41,708 Stage-8 map = 0%,  reduce = 0%
2016-10-01 11:28:52,001 Stage-8 map = 33%,  reduce = 0%, Cumulative CPU 7.27 sec
2016-10-01 11:28:54,070 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 9.48 sec
2016-10-01 11:29:00,235 Stage-8 map = 100%,  reduce = 100%, Cumulative CPU 11.27 sec
MapReduce Total cumulative CPU time: 11 seconds 270 msec
Ended Job = job_1475271333482_0180
Launching Job 9 out of 16
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475271333482_0181, Tracking URL = http://vm1:8088/proxy/application_1475271333482_0181/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475271333482_0181
Hadoop job information for Stage-9: number of mappers: 1; number of reducers: 1
2016-10-01 11:29:07,036 Stage-9 map = 0%,  reduce = 0%
2016-10-01 11:29:13,252 Stage-9 map = 100%,  reduce = 0%, Cumulative CPU 1.16 sec
2016-10-01 11:29:18,402 Stage-9 map = 100%,  reduce = 100%, Cumulative CPU 2.46 sec
MapReduce Total cumulative CPU time: 2 seconds 460 msec
Ended Job = job_1475271333482_0181
MapReduce Jobs Launched: 
Stage-Stage-1: Map: 30  Reduce: 32   Cumulative CPU: 554.43 sec   HDFS Read: 8124263543 HDFS Write: 226967742 SUCCESS
Stage-Stage-30: Map: 4   Cumulative CPU: 37.29 sec   HDFS Read: 227005634 HDFS Write: 235481511 SUCCESS
Stage-Stage-3: Map: 5  Reduce: 2   Cumulative CPU: 84.4 sec   HDFS Read: 316193629 HDFS Write: 293830062 SUCCESS
Stage-Stage-4: Map: 6  Reduce: 2   Cumulative CPU: 90.92 sec   HDFS Read: 374560446 HDFS Write: 348836512 SUCCESS
Stage-Stage-5: Map: 3  Reduce: 2   Cumulative CPU: 87.06 sec   HDFS Read: 391383855 HDFS Write: 419920253 SUCCESS
Stage-Stage-18: Map: 2   Cumulative CPU: 22.16 sec   HDFS Read: 419948063 HDFS Write: 85556527 SUCCESS
Stage-Stage-8: Map: 1  Reduce: 1   Cumulative CPU: 11.27 sec   HDFS Read: 85590129 HDFS Write: 1858 SUCCESS
Stage-Stage-9: Map: 1  Reduce: 1   Cumulative CPU: 2.46 sec   HDFS Read: 7071 HDFS Write: 1783 SUCCESS
Total MapReduce CPU Time Spent: 14 minutes 49 seconds 990 msec
OK
Time taken: 379.658 seconds, Fetched: 32 row(s)
51.15user 5.45system 6:27.33elapsed 14%CPU (0avgtext+0avgdata 1189644maxresident)k
115552inputs+492080outputs (109major+203732minor)pagefaults 0swaps
