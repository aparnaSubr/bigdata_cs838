
Logging initialized using configuration in jar:file:/home/ubuntu/software/hive-1.2.1/lib/hive-common-1.2.1.jar!/hive-log4j.properties
Hive history file=/tmp/ubuntu/hive_job_log_001bc613-ce7c-450d-8ca5-c545744f0921_778803478.txt
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
OK
Time taken: 1.101 seconds
Query ID = ubuntu_20161002171944_411a9e46-8990-414f-ac4c-59dd3170b227
Total jobs = 8
Stage-16 is selected by condition resolver.
Stage-1 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161002171944_411a9e46-8990-414f-ac4c-59dd3170b227.log
2016-10-02 17:19:50	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-02 17:19:52	Dump the side-table for tag: 1 with group count: 18445 into file: file:/tmp/ubuntu/001bc613-ce7c-450d-8ca5-c545744f0921/hive_2016-10-02_17-19-44_326_6753542981473727526-1/-local-10012/HashTable-Stage-11/MapJoin-mapfile21--.hashtable
2016-10-02 17:19:52	Uploaded 1 File to: file:/tmp/ubuntu/001bc613-ce7c-450d-8ca5-c545744f0921/hive_2016-10-02_17-19-44_326_6753542981473727526-1/-local-10012/HashTable-Stage-11/MapJoin-mapfile21--.hashtable (2960337 bytes)
2016-10-02 17:19:52	End of local task; Time Taken: 2.109 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 2 out of 8
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1475426732253_0036, Tracking URL = http://vm1:8088/proxy/application_1475426732253_0036/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475426732253_0036
Hadoop job information for Stage-11: number of mappers: 26; number of reducers: 0
2016-10-02 17:20:02,414 Stage-11 map = 0%,  reduce = 0%
2016-10-02 17:20:14,005 Stage-11 map = 1%,  reduce = 0%, Cumulative CPU 15.31 sec
2016-10-02 17:20:15,039 Stage-11 map = 3%,  reduce = 0%, Cumulative CPU 59.75 sec
2016-10-02 17:20:20,236 Stage-11 map = 9%,  reduce = 0%, Cumulative CPU 96.95 sec
2016-10-02 17:20:21,278 Stage-11 map = 23%,  reduce = 0%, Cumulative CPU 103.83 sec
2016-10-02 17:20:22,315 Stage-11 map = 30%,  reduce = 0%, Cumulative CPU 107.4 sec
2016-10-02 17:20:23,348 Stage-11 map = 32%,  reduce = 0%, Cumulative CPU 110.7 sec
2016-10-02 17:20:24,387 Stage-11 map = 34%,  reduce = 0%, Cumulative CPU 117.41 sec
2016-10-02 17:20:27,502 Stage-11 map = 38%,  reduce = 0%, Cumulative CPU 130.76 sec
2016-10-02 17:20:29,564 Stage-11 map = 39%,  reduce = 0%, Cumulative CPU 136.28 sec
2016-10-02 17:20:30,600 Stage-11 map = 53%,  reduce = 0%, Cumulative CPU 141.98 sec
2016-10-02 17:20:31,635 Stage-11 map = 56%,  reduce = 0%, Cumulative CPU 143.98 sec
2016-10-02 17:20:34,728 Stage-11 map = 62%,  reduce = 0%, Cumulative CPU 145.88 sec
2016-10-02 17:20:37,822 Stage-11 map = 65%,  reduce = 0%, Cumulative CPU 158.19 sec
2016-10-02 17:20:38,860 Stage-11 map = 66%,  reduce = 0%, Cumulative CPU 163.22 sec
2016-10-02 17:20:39,901 Stage-11 map = 69%,  reduce = 0%, Cumulative CPU 167.1 sec
2016-10-02 17:20:40,933 Stage-11 map = 70%,  reduce = 0%, Cumulative CPU 181.13 sec
2016-10-02 17:20:41,966 Stage-11 map = 72%,  reduce = 0%, Cumulative CPU 188.34 sec
2016-10-02 17:20:44,035 Stage-11 map = 78%,  reduce = 0%, Cumulative CPU 206.23 sec
2016-10-02 17:20:46,094 Stage-11 map = 82%,  reduce = 0%, Cumulative CPU 210.81 sec
2016-10-02 17:20:47,128 Stage-11 map = 84%,  reduce = 0%, Cumulative CPU 214.45 sec
2016-10-02 17:20:48,162 Stage-11 map = 89%,  reduce = 0%, Cumulative CPU 216.23 sec
2016-10-02 17:20:49,200 Stage-11 map = 90%,  reduce = 0%, Cumulative CPU 219.25 sec
2016-10-02 17:20:51,256 Stage-11 map = 93%,  reduce = 0%, Cumulative CPU 223.46 sec
2016-10-02 17:20:52,287 Stage-11 map = 95%,  reduce = 0%, Cumulative CPU 225.19 sec
2016-10-02 17:20:53,315 Stage-11 map = 97%,  reduce = 0%, Cumulative CPU 226.5 sec
2016-10-02 17:20:54,343 Stage-11 map = 99%,  reduce = 0%, Cumulative CPU 227.73 sec
2016-10-02 17:20:55,372 Stage-11 map = 100%,  reduce = 0%, Cumulative CPU 229.13 sec
MapReduce Total cumulative CPU time: 3 minutes 49 seconds 130 msec
Ended Job = job_1475426732253_0036
Stage-14 is selected by condition resolver.
Stage-15 is filtered out by condition resolver.
Stage-2 is filtered out by condition resolver.
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/ubuntu/software/tez-0.7.1-SNAPSHOT-minimal/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Execution log at: /tmp/ubuntu/ubuntu_20161002171944_411a9e46-8990-414f-ac4c-59dd3170b227.log
2016-10-02 17:21:00	Starting to launch local task to process map join;	maximum memory = 932184064
2016-10-02 17:21:02	Dump the side-table for tag: 1 with group count: 31 into file: file:/tmp/ubuntu/001bc613-ce7c-450d-8ca5-c545744f0921/hive_2016-10-02_17-19-44_326_6753542981473727526-1/-local-10008/HashTable-Stage-8/MapJoin-mapfile01--.hashtable
2016-10-02 17:21:02	Uploaded 1 File to: file:/tmp/ubuntu/001bc613-ce7c-450d-8ca5-c545744f0921/hive_2016-10-02_17-19-44_326_6753542981473727526-1/-local-10008/HashTable-Stage-8/MapJoin-mapfile01--.hashtable (1288 bytes)
2016-10-02 17:21:02	End of local task; Time Taken: 1.832 sec.
Execution completed successfully
MapredLocal task succeeded
Launching Job 4 out of 8
Number of reduce tasks is set to 0 since there's no reduce operator
Starting Job = job_1475426732253_0037, Tracking URL = http://vm1:8088/proxy/application_1475426732253_0037/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475426732253_0037
Hadoop job information for Stage-8: number of mappers: 7; number of reducers: 0
2016-10-02 17:21:07,931 Stage-8 map = 0%,  reduce = 0%
2016-10-02 17:21:19,346 Stage-8 map = 57%,  reduce = 0%, Cumulative CPU 27.66 sec
2016-10-02 17:21:20,386 Stage-8 map = 72%,  reduce = 0%, Cumulative CPU 39.69 sec
2016-10-02 17:21:21,428 Stage-8 map = 79%,  reduce = 0%, Cumulative CPU 45.56 sec
2016-10-02 17:21:22,468 Stage-8 map = 93%,  reduce = 0%, Cumulative CPU 48.8 sec
2016-10-02 17:21:23,505 Stage-8 map = 100%,  reduce = 0%, Cumulative CPU 51.23 sec
MapReduce Total cumulative CPU time: 51 seconds 230 msec
Ended Job = job_1475426732253_0037
Launching Job 5 out of 8
Number of reduce tasks not specified. Defaulting to jobconf value of: 20
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475426732253_0038, Tracking URL = http://vm1:8088/proxy/application_1475426732253_0038/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475426732253_0038
Hadoop job information for Stage-3: number of mappers: 4; number of reducers: 20
2016-10-02 17:21:29,361 Stage-3 map = 0%,  reduce = 0%
2016-10-02 17:21:38,774 Stage-3 map = 100%,  reduce = 0%, Cumulative CPU 9.51 sec
2016-10-02 17:21:45,030 Stage-3 map = 100%,  reduce = 20%, Cumulative CPU 16.23 sec
2016-10-02 17:21:46,094 Stage-3 map = 100%,  reduce = 40%, Cumulative CPU 22.79 sec
2016-10-02 17:21:47,174 Stage-3 map = 100%,  reduce = 55%, Cumulative CPU 26.14 sec
2016-10-02 17:21:48,221 Stage-3 map = 100%,  reduce = 75%, Cumulative CPU 34.46 sec
2016-10-02 17:21:49,269 Stage-3 map = 100%,  reduce = 80%, Cumulative CPU 36.1 sec
2016-10-02 17:21:50,314 Stage-3 map = 100%,  reduce = 100%, Cumulative CPU 42.49 sec
MapReduce Total cumulative CPU time: 42 seconds 490 msec
Ended Job = job_1475426732253_0038
Launching Job 6 out of 8
Number of reduce tasks not specified. Defaulting to jobconf value of: 20
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475426732253_0039, Tracking URL = http://vm1:8088/proxy/application_1475426732253_0039/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475426732253_0039
Hadoop job information for Stage-4: number of mappers: 4; number of reducers: 20
2016-10-02 17:21:57,241 Stage-4 map = 0%,  reduce = 0%
2016-10-02 17:22:05,537 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 7.54 sec
2016-10-02 17:22:11,800 Stage-4 map = 100%,  reduce = 5%, Cumulative CPU 9.35 sec
2016-10-02 17:22:12,849 Stage-4 map = 100%,  reduce = 20%, Cumulative CPU 14.91 sec
2016-10-02 17:22:13,924 Stage-4 map = 100%,  reduce = 40%, Cumulative CPU 22.84 sec
2016-10-02 17:22:14,973 Stage-4 map = 100%,  reduce = 45%, Cumulative CPU 24.85 sec
2016-10-02 17:22:16,012 Stage-4 map = 100%,  reduce = 80%, Cumulative CPU 38.25 sec
2016-10-02 17:22:18,081 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 45.2 sec
MapReduce Total cumulative CPU time: 45 seconds 200 msec
Ended Job = job_1475426732253_0039
Launching Job 7 out of 8
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1475426732253_0040, Tracking URL = http://vm1:8088/proxy/application_1475426732253_0040/
Kill Command = /home/ubuntu/software/hadoop-2.6.0/bin/hadoop job  -kill job_1475426732253_0040
Hadoop job information for Stage-5: number of mappers: 4; number of reducers: 1
2016-10-02 17:22:23,980 Stage-5 map = 0%,  reduce = 0%
2016-10-02 17:22:32,301 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 7.69 sec
2016-10-02 17:22:38,498 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 9.34 sec
MapReduce Total cumulative CPU time: 9 seconds 340 msec
Ended Job = job_1475426732253_0040
MapReduce Jobs Launched: 
Stage-Stage-11: Map: 26   Cumulative CPU: 229.69 sec   HDFS Read: 7607676612 HDFS Write: 1850142725 SUCCESS
Stage-Stage-8: Map: 7   Cumulative CPU: 51.23 sec   HDFS Read: 1850232868 HDFS Write: 8228480 SUCCESS
Stage-Stage-3: Map: 4  Reduce: 20   Cumulative CPU: 42.49 sec   HDFS Read: 8300431 HDFS Write: 1534722 SUCCESS
Stage-Stage-4: Map: 4  Reduce: 20   Cumulative CPU: 45.2 sec   HDFS Read: 1668886 HDFS Write: 1609446 SUCCESS
Stage-Stage-5: Map: 4  Reduce: 1   Cumulative CPU: 9.34 sec   HDFS Read: 1627691 HDFS Write: 18517 SUCCESS
Total MapReduce CPU Time Spent: 6 minutes 17 seconds 950 msec
OK
Time taken: 175.267 seconds, Fetched: 100 row(s)
36.82user 3.11system 3:02.82elapsed 21%CPU (0avgtext+0avgdata 747620maxresident)k
114920inputs+315992outputs (109major+147809minor)pagefaults 0swaps
